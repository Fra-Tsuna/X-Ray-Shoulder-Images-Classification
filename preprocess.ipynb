{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('gym': conda)",
   "metadata": {
    "interpreter": {
     "hash": "176d77b17fed6a66bcc6c4a30d5abc02d3cd726b8914b0a8063a0addb6f260c1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Libraries imported\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "print(\"Libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocesser:\n",
    "\n",
    "    def __init__(self, input_csv, output_path, labels_path, limit):\n",
    "        with open(input_csv) as fp:\n",
    "            rows = list(csv.reader(fp))\n",
    "\n",
    "        self.X=[]\n",
    "        self.y=[]\n",
    "\n",
    "        count = 0\n",
    "        for row in rows:\n",
    "            img=cv2.imread(row[0],1)\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            self.X.append(gray)\n",
    "            if row[0][48]=='p':\n",
    "                self.y.append(1)\n",
    "            else:\n",
    "                self.y.append(0)\n",
    "            count=count+1\n",
    "            if count==limit:\n",
    "                break\n",
    "        \n",
    "        self.Xp=self.preprocess(self.X)\n",
    "        self.savedata(self.Xp, self.y, output_path, labels_path)\n",
    "\n",
    "\n",
    "    def preprocess(self, X):\n",
    "        Xp=[]\n",
    "        for i in range(len(X)):\n",
    "            img = X[i]\n",
    "            thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "            x,y,w,h=cv2.boundingRect(thresh)\n",
    "            x,y,w,h=x,y,w+20,h+20\n",
    "            img = img[y:y+h, x:x+w]\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "            Xp.append(clahe.apply(img))\n",
    "        return Xp\n",
    "    \n",
    "    def savedata(self, data, labels, path, labels_path):\n",
    "        for i in range(len(data)):\n",
    "            if self.y[i] == 1:\n",
    "                cv2.imwrite(path+'/abnormal/'+str(i)+\".png\",data[i])\n",
    "            else:\n",
    "                cv2.imwrite(path+'/normal/'+str(i)+\".png\",data[i])\n",
    "        with open(labels_path, \"wb\") as fp:\n",
    "            pickle.dump(labels, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<__main__.preprocesser at 0x20d62793c40>"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "training_data = \"train_image_paths.csv\"\n",
    "training_path = \"Dataset/train/\"\n",
    "train_labels = \"train_labels.txt\"\n",
    "limit=8379\n",
    "\n",
    "preprocesser(training_data, training_path, train_labels, limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<__main__.preprocesser at 0x20d62c1b910>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "testing_data = \"valid_image_paths.csv\"\n",
    "testing_path = \"Dataset/test/\"\n",
    "test_labels = \"test_labels.txt\"\n",
    "limit = 563\n",
    "\n",
    "preprocesser(testing_data, testing_path, test_labels, limit)"
   ]
  }
 ]
}